{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc054a1-df2d-4355-89e9-1801a1a6a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fb0dac-b2c9-4c89-8b72-667dca5336f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0d9292-4e0a-45e2-8b3c-16ccbfb4ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 572 'surprise' tweets\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and prepare \"surprise\" tweets\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 1. Load emotion dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# 2. Get \"surprise\" tweets (label=5)\n",
    "surprise_tweets = df[df[\"label\"] == 5][\"text\"].tolist()\n",
    "\n",
    "# 3. Tokenize with BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "inputs = tokenizer(surprise_tweets, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "\n",
    "# 4. Get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    real_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "print(f\"Preprocessed {len(real_embeddings)} 'surprise' tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ccc4ab-9214-44fc-ac6e-353ec67dee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(100 + 6, 256),  # Noise (100) + one-hot label (6 emotions)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 768)  # Output size = BERT embedding size\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise, labels):\n",
    "        one_hot = torch.zeros(labels.size(0), 6)\n",
    "        one_hot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "        x = torch.cat([noise, one_hot], dim=1)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a02114e-12c4-4113-9102-9941ad682764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(768 + 6, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, emb, labels):\n",
    "        one_hot = torch.zeros(labels.size(0), 6)\n",
    "        one_hot.scatter_(1, labels.unsqueeze(1), 1)\n",
    "        x = torch.cat([emb, one_hot], dim=1)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d36859f-97c1-488e-99a9-50cb605dfa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D_loss=1.3844, G_loss=0.6940\n",
      "Epoch 100: D_loss=0.7941, G_loss=1.2693\n",
      "Epoch 200: D_loss=0.7440, G_loss=1.6468\n",
      "Epoch 300: D_loss=0.3233, G_loss=2.4636\n",
      "Epoch 400: D_loss=0.3661, G_loss=1.8779\n",
      "Epoch 500: D_loss=0.7391, G_loss=1.0690\n",
      "Epoch 600: D_loss=0.8308, G_loss=1.0031\n",
      "Epoch 700: D_loss=0.6263, G_loss=1.3456\n",
      "Epoch 800: D_loss=0.6436, G_loss=1.3527\n",
      "Epoch 900: D_loss=1.1535, G_loss=0.9475\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    # Real data\n",
    "    real_emb = real_embeddings.to(device)\n",
    "    real_labels = torch.full((32,), 5).to(device)  # All \"surprise\"\n",
    "    \n",
    "    # Train Discriminator\n",
    "    noise = torch.randn(32, 100).to(device)\n",
    "    fake_emb = generator(noise, real_labels)\n",
    "    \n",
    "    d_real = discriminator(real_emb[:32], real_labels)\n",
    "    d_fake = discriminator(fake_emb.detach(), real_labels)\n",
    "    d_loss = -(torch.log(d_real).mean() + torch.log(1 - d_fake).mean())\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    # Train Generator\n",
    "    g_loss = -torch.log(discriminator(fake_emb, real_labels)).mean()\n",
    "    optimizer_G.zero_grad()\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: D_loss={d_loss.item():.4f}, G_loss={g_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72421ed-c5c8-456d-953c-cf492ff359c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000 synthetic 'surprise' samples!\n"
     ]
    }
   ],
   "source": [
    "# Generate fake \"surprise\" tweets\n",
    "noise = torch.randn(1000, 100).to(device)\n",
    "fake_labels = torch.full((1000,), 5).to(device)  # All \"surprise\"\n",
    "fake_embeddings = generator(noise, fake_labels)\n",
    "\n",
    "# Save for later\n",
    "torch.save(fake_embeddings, \"fake_surprise_embeddings.pt\")\n",
    "print(\"Generated 1000 synthetic 'surprise' samples!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
